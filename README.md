## Statistical Markov Language Models
- are based on counting of words and
- are precursor to modern word embeddings such as Word2Vec,  

* Before attempting the best-in-class Language models (pre-trained or otherwise) that involve seq2seq networks and transformers, I wanted to take a step back and understand the fundamentals better
* That is the reason behind developing codes and notes for Bigram and Trigram Markov Language Models.
* The below link has my notes on `Statistical Markov Language Models`: <br>
https://senthilkumarm1901.github.io/StatisticalLanguageModels/
