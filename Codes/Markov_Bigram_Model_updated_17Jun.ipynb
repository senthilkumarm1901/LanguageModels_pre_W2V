{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a15a75a7b26c7ef93cbb41a271141d3a29ab7298"
   },
   "source": [
    "https://pdfs.semanticscholar.org/presentation/b2ac/7b9e690272f87131477dffa627c8179cc91c.pdf<br>https://web.stanford.edu/~jurafsky/slp3/4.pdf <br>\n",
    "What are language models? <br>\n",
    "\n",
    "https://sookocheff.com/post/nlp/n-gram-modeling/<br>\n",
    "\n",
    "https://d3c33hcgiwev3.cloudfront.net/_aa08682f2130e183c01bb5851d06f60b_w2_l1_e1_new.pdf?Expires=1529366400&Signature=Fd2eYWMHH366t93TOv58dLR3A8i0EGLR3-XCOJeOcNIa54PphnqmuULXVv0-6vAwl4Gl~xmfWcuiDTdFBa~eGksOGlP1S1pf3P5dXWwtBvoSD57P1ZZzB3PYdcA3VIpD6em5r3YK3yvty4fjGmZg398TvXGt8pdIj0~ygMNEg3A_&Key-Pair-Id=APKAJLTNE6QMUY6HBC5A <br>\n",
    "https://www.coursera.org/learn/language-processing/lecture/IdJFl/count-n-gram-language-models<br>\n",
    "Coursera - PDF and Link to the Video<br>\n",
    "\n",
    "https://github.com/lmc2179/ngram-language-model<br>\n",
    "\n",
    "http://www.cs.cmu.edu/~bhiksha/courses/11-756.asr/spring2010/class.19apr/ngrams.pdf<br>\n",
    "\n",
    "Next Topic is Hidden Markov Models:\n",
    "http://www.cs.cmu.edu/~bhiksha/courses/11-756.asr/spring2010/class.19apr/ngrams.pdf<br>\n",
    "https://www.youtube.com/watch?v=HVAwc0SOEoQ<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "d3c0517c870ebb21641a1eb3ee2c0e960af4ea8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "259013e0cf97551f7ae6660bf5fc0839be610f74"
   },
   "outputs": [],
   "source": [
    "news_text = brown.sents(categories='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "46b23f94d3e0bd091cdd52aa6adb02b69cb9f054"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ['The', 'September-October', 'term', 'jury', 'had', 'been', 'charged', 'by', 'Fulton', 'Superior', 'Court', 'Judge', 'Durwood', 'Pye', 'to', 'investigate', 'reports', 'of', 'possible', '``', 'irregularities', \"''\", 'in', 'the', 'hard-fought', 'primary', 'which', 'was', 'won', 'by', 'Mayor-nominate', 'Ivan', 'Allen', 'Jr.', '.'], ['``', 'Only', 'a', 'relative', 'handful', 'of', 'such', 'reports', 'was', 'received', \"''\", ',', 'the', 'jury', 'said', ',', '``', 'considering', 'the', 'widespread', 'interest', 'in', 'the', 'election', ',', 'the', 'number', 'of', 'voters', 'and', 'the', 'size', 'of', 'this', 'city', \"''\", '.'], ['The', 'jury', 'said', 'it', 'did', 'find', 'that', 'many', 'of', \"Georgia's\", 'registration', 'and', 'election', 'laws', '``', 'are', 'outmoded', 'or', 'inadequate', 'and', 'often', 'ambiguous', \"''\", '.']]\n"
     ]
    }
   ],
   "source": [
    "print (news_text[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "0160cea2da6424d77c43da9044009d93ffd5fcc0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "news_text_lowered=[[each_word.lower() for each_word in each_sent] for each_sent in news_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "feee5de7bb0d74b5735cb7d54517c60eef341ba2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13112 100554\n"
     ]
    }
   ],
   "source": [
    "news_text_lowered_list=[each_word for each_sent in news_text_lowered for each_word in each_sent]\n",
    "Unique_words=list(set(news_text_lowered_list))\n",
    "vocab_size=len(Unique_words)\n",
    "no_of_words=len(news_text_lowered_list)\n",
    "print (vocab_size,no_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "d7481110e373ee0e5b74429f9cce38b3d8072ec0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('the', 'fulton'), ('fulton', 'county'), ('county', 'grand'), ('grand', 'jury'), ('jury', 'said'), ('said', 'friday'), ('friday', 'an'), ('an', 'investigation'), ('investigation', 'of'), ('of', \"atlanta's\"), (\"atlanta's\", 'recent'), ('recent', 'primary'), ('primary', 'election'), ('election', 'produced'), ('produced', '``'), ('``', 'no'), ('no', 'evidence'), ('evidence', \"''\"), (\"''\", 'that'), ('that', 'any'), ('any', 'irregularities'), ('irregularities', 'took'), ('took', 'place'), ('place', '.')], [('the', 'jury'), ('jury', 'further'), ('further', 'said'), ('said', 'in'), ('in', 'term-end'), ('term-end', 'presentments'), ('presentments', 'that'), ('that', 'the'), ('the', 'city'), ('city', 'executive'), ('executive', 'committee'), ('committee', ','), (',', 'which'), ('which', 'had'), ('had', 'over-all'), ('over-all', 'charge'), ('charge', 'of'), ('of', 'the'), ('the', 'election'), ('election', ','), (',', '``'), ('``', 'deserves'), ('deserves', 'the'), ('the', 'praise'), ('praise', 'and'), ('and', 'thanks'), ('thanks', 'of'), ('of', 'the'), ('the', 'city'), ('city', 'of'), ('of', 'atlanta'), ('atlanta', \"''\"), (\"''\", 'for'), ('for', 'the'), ('the', 'manner'), ('manner', 'in'), ('in', 'which'), ('which', 'the'), ('the', 'election'), ('election', 'was'), ('was', 'conducted'), ('conducted', '.')]]\n"
     ]
    }
   ],
   "source": [
    "def bigrams(input_list):\n",
    "    return list(zip(input_list,input_list[1:]))\n",
    "bigrams_list=[bigrams(each_sent) for each_sent in news_text_lowered]\n",
    "print (bigrams_list[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "6fd1356d48908eebd6ce0d6a112c15bb874443e3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigrams_single_list=[each_word for each_sent in bigrams_list for each_word in each_sent]\n",
    "#flat_list = [item for sublist in l for item in sublist]\n",
    "Count_dict_bigrams=Counter(bigrams_single_list)\n",
    "Count_dict_unigrams=Counter(news_text_lowered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "b5d8edd4d12b66f175fc9b3523f9494c3389d671",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Markov(new_sent):\n",
    "    new_sent=new_sent.lower()\n",
    "    new_words=new_sent.split()\n",
    "    new_bigrams=bigrams(new_words)\n",
    "    Markov_prob=0\n",
    "    for each in new_bigrams:\n",
    "        #print (np.log(Count_dict_bigrams[each]+1/(Count_dict_unigrams[each[0]]+vocab_size)))\n",
    "        Markov_prob+=np.log((Count_dict_bigrams[each]+0.1)/(Count_dict_unigrams[each[0]]+vocab_size)) #0.1 is the add-one smoothing\n",
    "    Markov_prob+=np.log((Count_dict_unigrams[new_words[0]]+0.1)/(no_of_words))\n",
    "    return Markov_prob/len(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "b94f601c449310678805dfa0dbfeb97b8794d17a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7.53636837185\n",
      "-10.3185123339\n",
      "-8.58391482829\n",
      "-12.2931599772\n"
     ]
    }
   ],
   "source": [
    "print (Markov(\"the fulton county jury said\"))\n",
    "print (Markov(\"some random statement is this\"))\n",
    "print (Markov('only a relative handful of such reports'))\n",
    "print (Markov(\"ramdndomm fhlkh kjkel kjlk\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
